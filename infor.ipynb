{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF CSV Columns:\n",
      " Index(['source_id', 'source_name', 'iso3_country', 'original_inventory_sector',\n",
      "       'lat', 'lon', 'geometry_ref', 'relationship', 'ultimate_parent_name',\n",
      "       'ultimate_parent_id', 'percent_interest_parent', 'company_name',\n",
      "       'company_id', 'percent_interest_company', 'interest_units',\n",
      "       'start_date', 'end_date', 'created_date', 'modified_date',\n",
      "       'percent_company_datasource', 'percent_parent_datasource'],\n",
      "      dtype='object')\n",
      "DF XLSX Columns:\n",
      " Index(['Date Last Researched', 'Country', 'Project Name', 'Unit Name',\n",
      "       'Project Name in Local Language / Script', 'Other Name(s)',\n",
      "       'Capacity (MW)', 'Status', 'Reactor Type', 'Model', 'Start Year',\n",
      "       'Retirement Year', 'Planned Retirement', 'Cancellation Year',\n",
      "       'Construction Start Date', 'First Criticality Date',\n",
      "       'First Grid Connection', 'Commercial Operation Date', 'Retirement Date',\n",
      "       'Owner', 'Owner Name in Local Language / Script', 'Operator',\n",
      "       'Operator Name in Local Language / Script',\n",
      "       'Reference Net Capacity (MW)', 'Design Net Capacity (MW)',\n",
      "       'Thermal Capacity (MWt)', 'Latitude', 'Longitude', 'Location Accuracy',\n",
      "       'City', 'Local Area (taluk, county)',\n",
      "       'Major Area (prefecture, district)', 'State/Province', 'Subregion',\n",
      "       'Region', 'GEM location ID', 'GEM unit ID', 'Wiki URL'],\n",
      "      dtype='object')\n",
      "Standardized DF CSV Columns:\n",
      " Index(['source_id', 'source_name', 'iso3_country', 'original_inventory_sector',\n",
      "       'lat', 'lon', 'geometry_ref', 'relationship', 'ultimate_parent_name',\n",
      "       'ultimate_parent_id', 'percent_interest_parent', 'company_name',\n",
      "       'company_id', 'percent_interest_company', 'interest_units',\n",
      "       'start_date', 'end_date', 'created_date', 'modified_date',\n",
      "       'percent_company_datasource', 'percent_parent_datasource'],\n",
      "      dtype='object')\n",
      "Standardized DF XLSX Columns:\n",
      " Index(['date_last_researched', 'country', 'project_name', 'unit_name',\n",
      "       'project_name_in_local_language_/_script', 'other_name(s)',\n",
      "       'capacity_(mw)', 'status', 'reactor_type', 'model', 'start_year',\n",
      "       'retirement_year', 'planned_retirement', 'cancellation_year',\n",
      "       'construction_start_date', 'first_criticality_date',\n",
      "       'first_grid_connection', 'commercial_operation_date', 'retirement_date',\n",
      "       'owner', 'owner_name_in_local_language_/_script', 'operator',\n",
      "       'operator_name_in_local_language_/_script',\n",
      "       'reference_net_capacity_(mw)', 'design_net_capacity_(mw)',\n",
      "       'thermal_capacity_(mwt)', 'latitude', 'longitude', 'location_accuracy',\n",
      "       'city', 'local_area_(taluk,_county)',\n",
      "       'major_area_(prefecture,_district)', 'state/province', 'subregion',\n",
      "       'region', 'gem_location_id', 'gem_unit_id', 'wiki_url'],\n",
      "      dtype='object')\n",
      "Some matched company names:\n",
      "                                         company_name  \\\n",
      "0                                          WEB Aruba   \n",
      "1                                            Sonag√°s   \n",
      "2              Dubai Electricity and Water Authority   \n",
      "3  Federal Electricity and Water Authority (Unite...   \n",
      "4                          Emirates Global Aluminium   \n",
      "\n",
      "                              matched_company_name  \n",
      "0                                    Alabama Power  \n",
      "1                                              NaN  \n",
      "2  US DOE and Puerto Rico Electric Power Authority  \n",
      "3                        Vietnam Electricity (EVN)  \n",
      "4                     Emirates Nuclear Energy CORP  \n",
      "Merged DataFrame Head:\n",
      "    source_id        source_name iso3_country original_inventory_sector  \\\n",
      "0   25457366  RECIP power plant          ABW    electricity-generation   \n",
      "1   25457366  RECIP power plant          ABW    electricity-generation   \n",
      "2   25457366  RECIP power plant          ABW    electricity-generation   \n",
      "3   25457366  RECIP power plant          ABW    electricity-generation   \n",
      "4   25457366  RECIP power plant          ABW    electricity-generation   \n",
      "\n",
      "      lat      lon           geometry_ref relationship ultimate_parent_name  \\\n",
      "0  12.476 -69.9822  trace_-69.9822_12.476        owner            WEB Aruba   \n",
      "1  12.476 -69.9822  trace_-69.9822_12.476        owner            WEB Aruba   \n",
      "2  12.476 -69.9822  trace_-69.9822_12.476        owner            WEB Aruba   \n",
      "3  12.476 -69.9822  trace_-69.9822_12.476        owner            WEB Aruba   \n",
      "4  12.476 -69.9822  trace_-69.9822_12.476        owner            WEB Aruba   \n",
      "\n",
      "   ultimate_parent_id  ...  location_accuracy city  \\\n",
      "0        1.000010e+11  ...              exact  NaN   \n",
      "1        1.000010e+11  ...              exact  NaN   \n",
      "2        1.000010e+11  ...              exact  NaN   \n",
      "3        1.000010e+11  ...              exact  NaN   \n",
      "4        1.000010e+11  ...              exact  NaN   \n",
      "\n",
      "   local_area_(taluk,_county)  major_area_(prefecture,_district)  \\\n",
      "0               Elmore County                                NaN   \n",
      "1               Elmore County                                NaN   \n",
      "2               Elmore County                                NaN   \n",
      "3               Elmore County                                NaN   \n",
      "4              Houston County                                NaN   \n",
      "\n",
      "  state/province         subregion    region gem_location_id  gem_unit_id  \\\n",
      "0        Alabama  Northern America  Americas         L500460      G501328   \n",
      "1        Alabama  Northern America  Americas         L500460      G501329   \n",
      "2        Alabama  Northern America  Americas         L500460      G501330   \n",
      "3        Alabama  Northern America  Americas         L500460      G501331   \n",
      "4        Alabama  Northern America  Americas         L500140      G500320   \n",
      "\n",
      "                                            wiki_url  \n",
      "0  https://gem.wiki/Alan_R._Barton_nuclear_power_...  \n",
      "1  https://gem.wiki/Alan_R._Barton_nuclear_power_...  \n",
      "2  https://gem.wiki/Alan_R._Barton_nuclear_power_...  \n",
      "3  https://gem.wiki/Alan_R._Barton_nuclear_power_...  \n",
      "4  https://gem.wiki/Joseph_M_Farley_nuclear_power...  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Load the datasets\n",
    "df_csv = pd.read_csv(\"/workspaces/ETL-pipeline/dags/electricity-generation_emissions_sources_ownership.csv\")\n",
    "df_xlsx = pd.read_csv(\"/workspaces/ETL-pipeline/dags/Global-Nuclear-Power-Tracker-October-2023.csv\")\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"DF CSV Columns:\\n\", df_csv.columns)\n",
    "print(\"DF XLSX Columns:\\n\", df_xlsx.columns)\n",
    "\n",
    "# Standardize and clean column names\n",
    "df_csv.columns = df_csv.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df_xlsx.columns = df_xlsx.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Verify standardized column names\n",
    "print(\"Standardized DF CSV Columns:\\n\", df_csv.columns)\n",
    "print(\"Standardized DF XLSX Columns:\\n\", df_xlsx.columns)\n",
    "\n",
    "# Extract unique company names from both datasets\n",
    "company_names_csv = df_csv['company_name'].unique()\n",
    "company_names_xlsx = df_xlsx['owner'].unique()\n",
    "\n",
    "# Perform fuzzy matching to find the closest matches between company names\n",
    "matches = {name: process.extractOne(name, company_names_xlsx, scorer=fuzz.token_set_ratio)[0] for name in company_names_csv}\n",
    "df_csv['matched_company_name'] = df_csv['company_name'].map(matches)\n",
    "\n",
    "# Verify some of the matches\n",
    "print(\"Some matched company names:\\n\", df_csv[['company_name', 'matched_company_name']].head())\n",
    "\n",
    "# Merge the datasets based on the matched company names\n",
    "df_merged = pd.merge(df_csv, df_xlsx, left_on='matched_company_name', right_on='owner', suffixes=('_csv', '_xlsx'))\n",
    "\n",
    "# Print the merged DataFrame to verify\n",
    "print(\"Merged DataFrame Head:\\n\", df_merged.head())\n",
    "\n",
    "# Save the merged DataFrame to a CSV file for further analysis if needed\n",
    "#df_merged.to_csv(\"/workspaces/ETL-pipeline/dags/merged_company_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"/workspaces/ETL-pipeline/dags/merged_company_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Load the datasets\n",
    "df_power = pd.read_csv(\"/workspaces/ETL-pipeline/dags/electricity-generation_emissions_sources_ownership.csv\")\n",
    "df_nuclear = pd.read_csv(\"/workspaces/ETL-pipeline/dags/Global-Nuclear-Power-Tracker-October-2023.csv\")\n",
    "\n",
    "# # Clean and standardize column names\n",
    "# df_nuclear.columns = df_nuclear.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "# df_power.columns = df_power.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# # Extract unique company names from both datasets\n",
    "# company_names_nuclear = df_nuclear['owner'].unique()\n",
    "# company_names_power = df_power['company_name'].unique()\n",
    "\n",
    "# # Perform fuzzy matching to find the closest matches between company names\n",
    "# matches = {name: process.extractOne(name, company_names_nuclear, scorer=fuzz.token_set_ratio)[0] for name in company_names_power}\n",
    "# df_power['matched_company_name'] = df_power['company_name'].map(matches)\n",
    "\n",
    "# # Merge the datasets based on the matched company names\n",
    "# df_merged = pd.merge(df_power, df_nuclear, left_on='matched_company_name', right_on='owner', suffixes=('_power', '_nuclear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_df\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Run the processing and save to CSV\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_nuclear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_power\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# result_df.to_csv('processed_power_plants.csv', index=False)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData processing complete. Results saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_power_plants.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(nuclear_df, ownership_df)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Process nuclear power plant data\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m nuclear_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 27\u001b[0m     owners \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOwner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m owner \u001b[38;5;129;01min\u001b[39;00m owners:\n\u001b[1;32m     29\u001b[0m         parts \u001b[38;5;241m=\u001b[39m owner\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import datetime\n",
    "\n",
    "# Function to standardize company names\n",
    "def standardize_company_name(name):\n",
    "    return name.lower().replace(' sa', '').replace(' corp', '').strip()\n",
    "\n",
    "# Function to find the best match for a company name\n",
    "def find_best_match(name, existing_names, threshold=80):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for existing_name in existing_names:\n",
    "        score = fuzz.ratio(standardize_company_name(name), standardize_company_name(existing_name))\n",
    "        if score > best_score and score >= threshold:\n",
    "            best_match = existing_name\n",
    "            best_score = score\n",
    "    return best_match\n",
    "\n",
    "# Main processing function\n",
    "def process_data(nuclear_df, ownership_df):\n",
    "    # Create empty lists to store processed data\n",
    "    processed_data = []\n",
    "    \n",
    "    # Process nuclear power plant data\n",
    "    for _, row in nuclear_df.iterrows():\n",
    "        owners = row['Owner'].split(';')\n",
    "        for owner in owners:\n",
    "            parts = owner.split('[')\n",
    "            parent_company = parts[0].strip()\n",
    "            percent_interest = float(parts[1].strip('%]')) if len(parts) > 1 else 100.0\n",
    "            \n",
    "            processed_data.append({\n",
    "                'asset_name': row['Project Name'],\n",
    "                'asset_type': 'Nuclear Power Plant',\n",
    "                'unit_name': row['Unit Name'],\n",
    "                'capacity_mw': row['Capacity (MW)'],\n",
    "                'status': row['Status'],\n",
    "                'reactor_type': row['Reactor Type'],\n",
    "                'start_year': row['Start Year'],\n",
    "                'country': row['Country'],\n",
    "                'latitude': row['Latitude'],\n",
    "                'longitude': row['Longitude'],\n",
    "                'owner': parent_company,\n",
    "                'percent_interest': percent_interest\n",
    "            })\n",
    "\n",
    "    # Process ownership data\n",
    "    for _, row in ownership_df.iterrows():\n",
    "        processed_data.append({\n",
    "            'asset_name': row['source_name'],\n",
    "            'asset_type': 'Power Plant',\n",
    "            'unit_name': '',\n",
    "            'capacity_mw': None,\n",
    "            'status': None,\n",
    "            'reactor_type': None,\n",
    "            'start_year': None,\n",
    "            'country': row['iso3_country'],\n",
    "            'latitude': row['lat'],\n",
    "            'longitude': row['lon'],\n",
    "            'owner': row['ultimate_parent_name'],\n",
    "            'percent_interest': row['percent_interest_company']\n",
    "        })\n",
    "\n",
    "    # Convert processed data to DataFrame\n",
    "    result_df = pd.DataFrame(processed_data)\n",
    "    \n",
    "    # Add processing timestamp\n",
    "    result_df['processed_date'] = datetime.datetime.now()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Run the processing and save to CSV\n",
    "result_df = process_data(df_nuclear, df_power)\n",
    "# result_df.to_csv('processed_power_plants.csv', index=False)\n",
    "print(\"Data processing complete. Results saved to 'processed_power_plants.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
